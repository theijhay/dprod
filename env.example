# Dprod Environment Configuration
# ================================
# Copy this file to .env and adjust values as needed
# This configuration works out of the box with Docker Compose

# Environment
# -----------
NODE_ENV=development
DEBUG=true

# API Server Configuration
# ------------------------
PORT=8000
HOST=0.0.0.0

# Database Configuration
# ----------------------
# Default works with Docker Compose (postgres service)
# Format: postgresql+asyncpg://user:password@host:port/database
DATABASE_URL=postgresql+asyncpg://dprod:dprod@localhost:5432/dprod

# Redis Configuration
# -------------------
# Default works with Docker Compose (redis service)
# Format: redis://host:port
REDIS_URL=redis://localhost:6379

# Security
# --------
# Generate a secure secret key for production:
# python -c "import secrets; print(secrets.token_urlsafe(32))"
SECRET_KEY=your-secret-key-change-in-production
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# CORS Configuration
# ------------------
# JSON array format for multiple origins/hosts
ALLOWED_ORIGINS=["http://localhost:3000","http://localhost:8080"]
ALLOWED_HOSTS=["localhost","127.0.0.1"]

# Docker Configuration
# --------------------
# Path to Docker socket (default works on Linux/Mac)
DOCKER_SOCKET_PATH=/var/run/docker.sock

# File Upload Configuration
# --------------------------
MAX_FILE_SIZE=104857600  # 100MB in bytes
UPLOAD_PATH=/tmp/dprod/uploads

# OmniCoreAgent AI Configuration
# -------------------------------
# Enable/disable AI-powered analysis
AI_ENABLED=true
AI_FALLBACK_TO_RULES=true

# LLM Provider Configuration
LLM_PROVIDER=openai  # Options: openai, anthropic, groq, ollama
LLM_MODEL=gpt-4o-mini  # gpt-4o, gpt-4o-mini, claude-3-5-sonnet-20241022, etc.
LLM_API_KEY=your_openai_api_key_here

# Embedding Provider (for semantic memory)
EMBEDDING_PROVIDER=openai
EMBEDDING_MODEL=text-embedding-3-small

# OmniAgent Memory Configuration
OMNI_MEMORY_TYPE=in_memory  # Options: in_memory, redis, postgres, mysql, sqlite
OMNI_EVENT_TYPE=in_memory  # Options: in_memory, redis_stream

# Vector Database (optional, for semantic search)
# VECTOR_DB_TYPE=qdrant  # Options: qdrant, chromadb, mongodb
# QDRANT_URL=http://localhost:6333
# CHROMADB_PATH=/tmp/dprod/chromadb

# API URLs
# --------
# Used for CLI and frontend integration
API_URL=http://localhost:8000
NEXT_PUBLIC_API_URL=http://localhost:8000
DPROD_API_URL=http://localhost:8000

# Advanced Options
# ----------------
# Set to "true" to allow all host headers (useful for ALB/proxy setups)
ALLOW_ALL_HOSTS=false

# Set to "true" to skip database initialization on startup
DISABLE_DB_INIT=false

